{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Creating Severity Levels </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_135091/2549626132.py\", line 7, in <module>\n",
      "    import shap\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/shap/__init__.py\", line 4, in <module>\n",
      "    from .explainers import other\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/shap/explainers/__init__.py\", line 1, in <module>\n",
      "    from ._additive import AdditiveExplainer\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/shap/explainers/_additive.py\", line 4, in <module>\n",
      "    from ._explainer import Explainer\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/shap/explainers/_explainer.py\", line 8, in <module>\n",
      "    from .. import explainers, links, maskers, models\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/shap/maskers/__init__.py\", line 4, in <module>\n",
      "    from ._image import Image\n",
      "  File \"/home/wathsalya/.local/lib/python3.10/site-packages/shap/maskers/_image.py\", line 14, in <module>\n",
      "    import cv2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wathsalya/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /home/wathsalya/.local/lib/python3.10/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import silhouette_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import subprocess\n",
    "subprocess.check_call([\"pip\", \"install\", \"tabulate\"])\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"dementia_dataset_1.csv\")\n",
    "\n",
    "# List the columns you want to keep\n",
    "columns_to_keep = [\"Age\",\"Gender\",\"BMI\",\"FamilyHistoryAlzheimers\",\"Hypertension\",\"CardiovascularDisease\",\"MMSE\", \"ADL\", \"FunctionalAssessment\",\"MemoryComplaints\",\"BehavioralProblems\",\"Diagnosis\"]  \n",
    "\n",
    "# Keep only these columns\n",
    "data = data[columns_to_keep]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>FamilyHistoryAlzheimers</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>CardiovascularDisease</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>ADL</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender        BMI  FamilyHistoryAlzheimers  Hypertension  \\\n",
       "0   73       0  22.927749                        0             0   \n",
       "1   89       0  26.827681                        0             0   \n",
       "2   73       0  17.795882                        1             0   \n",
       "3   74       1  33.800817                        0             0   \n",
       "4   89       0  20.716974                        0             0   \n",
       "\n",
       "   CardiovascularDisease       MMSE       ADL  FunctionalAssessment  \\\n",
       "0                      0  21.463532  1.725883              6.518877   \n",
       "1                      0  20.613267  2.592424              7.118696   \n",
       "2                      0   7.356249  7.119548              5.895077   \n",
       "3                      0  13.991127  6.481226              8.965106   \n",
       "4                      0  13.517609  0.014691              6.045039   \n",
       "\n",
       "   MemoryComplaints  BehavioralProblems  Diagnosis  \n",
       "0                 0                   0          0  \n",
       "1                 0                   0          0  \n",
       "2                 0                   0          0  \n",
       "3                 0                   1          0  \n",
       "4                 0                   0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical features: features with more than 5 unique values are considered numerical\n",
    "num_cols = [\n",
    "    col for col in data.columns if col != \"Diagnosis\" and data[col].nunique() > 5\n",
    "]\n",
    "\n",
    "# Identify categorical features: features that are not numerical and not 'Diagnosis'\n",
    "cat_cols = data.columns.difference(num_cols).difference([\"Diagnosis\"]).to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21.463532\n",
       "1    20.613267\n",
       "2     7.356249\n",
       "3    13.991127\n",
       "4    13.517609\n",
       "Name: MMSE, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['MMSE'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cluster( data, cluster_features, target_column=\"Diagnosis\", n_clusters=3):\n",
    "\n",
    "    # Create a copy of the data\n",
    "    data_clustering = data.copy()\n",
    "\n",
    "    # Cluster ONLY dementia patients\n",
    "    dementia_mask = data_clustering[target_column] == 1\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(data_clustering[dementia_mask][cluster_features])\n",
    "\n",
    "    # Order clusters by MMSE (clinical relevance)\n",
    "    cluster_order = (\n",
    "        data_clustering[dementia_mask]\n",
    "        .groupby(clusters)[\"MMSE\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "        .index\n",
    "    )\n",
    "\n",
    "    # Print MMSE mean of each cluster\n",
    "    mmse_means = (\n",
    "        data_clustering[dementia_mask]\n",
    "        .groupby(clusters)[\"MMSE\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    print(\"MMSE mean of each cluster:\")\n",
    "    print(mmse_means, \"\\n\")\n",
    "\n",
    "    severity_mapping = {cluster_order[0]: 1, cluster_order[1]: 2, cluster_order[2]: 3}\n",
    "\n",
    "    # Update target variable\n",
    "    y = data_clustering[target_column].copy()\n",
    "    y[dementia_mask] = [severity_mapping[c] for c in clusters]\n",
    "    \n",
    "    # Update the clustered data with the new severity levels\n",
    "    data_clustering[\"Severity\"] = y\n",
    "\n",
    "    # Drop the Diagnosis column\n",
    "    data_clustering.drop(columns=[target_column], inplace=True)\n",
    "\n",
    "    # Calculate silhouette score\n",
    "    silhouette_avg = silhouette_score(\n",
    "        data_clustering[dementia_mask][cluster_features], clusters\n",
    "    )\n",
    "        \n",
    "    return {\n",
    "       \"clustered_data\": data_clustering,\n",
    "       \"silhouette_score\": silhouette_avg\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Various Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSE mean of each cluster:\n",
      "1    19.034165\n",
      "0    12.206746\n",
      "2     5.947568\n",
      "Name: MMSE, dtype: float64 \n",
      "\n",
      "Silhouette Score: 0.2388906321196244\n"
     ]
    }
   ],
   "source": [
    "# Filter features to exclude 'diagnose'\n",
    "cluster_features = [col for col in data.columns if col != \"Diagnosis\"]\n",
    "\n",
    "# Process clustering\n",
    "clustered_data = process_cluster(data, cluster_features)\n",
    "\n",
    "# Access results\n",
    "print(\"Silhouette Score:\", clustered_data[\"silhouette_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSE mean of each cluster:\n",
      "2    20.952587\n",
      "0    12.617803\n",
      "1     4.542357\n",
      "Name: MMSE, dtype: float64 \n",
      "\n",
      "Silhouette Score: 0.34887179487214776\n"
     ]
    }
   ],
   "source": [
    "cluster_features_2 = [\"MMSE\", \"FunctionalAssessment\", \"ADL\"]\n",
    "clustered_data_2 = process_cluster(data, cluster_features_2)\n",
    "\n",
    "# Access results\n",
    "print(\"Silhouette Score:\", clustered_data_2[\"silhouette_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSE mean of each cluster:\n",
      "0    21.080635\n",
      "2    12.860176\n",
      "1     4.639195\n",
      "Name: MMSE, dtype: float64 \n",
      "\n",
      "Silhouette Score: 0.4415287253461713\n"
     ]
    }
   ],
   "source": [
    "cluster_features_3 = ['MMSE', 'FunctionalAssessment']\n",
    "clustered_data_3 = process_cluster(data, cluster_features_3)\n",
    "\n",
    "# Access results\n",
    "print(\"Silhouette Score:\", clustered_data_3[\"silhouette_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSE mean of each cluster:\n",
      "2    20.904580\n",
      "0    12.492109\n",
      "1     4.486073\n",
      "Name: MMSE, dtype: float64 \n",
      "\n",
      "Silhouette Score: 0.5858768435462162\n"
     ]
    }
   ],
   "source": [
    "cluster_features_4 = ['MMSE']\n",
    "clustered_data_4 = process_cluster(data, cluster_features_4)\n",
    "\n",
    "# Access results\n",
    "print(\"Silhouette Score:\", clustered_data_4[\"silhouette_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after clustering:\n",
      "Severity\n",
      "0    1389\n",
      "2     314\n",
      "3     245\n",
      "1     201\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution after clustering:\")\n",
    "severity_counts = clustered_data[\"clustered_data\"][\"Severity\"].value_counts()\n",
    "print(severity_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering Silhouette Score and mean MMSE Scores, Cluster 4 is selected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test,name, model):\n",
    "   \n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "         \"model\": name,\n",
    "         \"accuracy\": accuracy_score(y_test, predictions) * 100,\n",
    "         \"precision\": precision_score(y_test, predictions, average=\"weighted\") * 100,  # Updated\n",
    "         \"recall\": recall_score(y_test, predictions, average=\"weighted\") * 100,        # Updated\n",
    "         \"f1\": f1_score(y_test, predictions, average=\"weighted\") * 100,    \n",
    "         \"roc_auc\": roc_auc_score(y_test, model.predict_proba(X_test), multi_class=\"ovr\") * 100\n",
    "         if hasattr(model, \"predict_proba\") else None,  # Htandle models without predict_proba\n",
    "         \"classification_report\": classification_report(y_test, predictions),\n",
    "         \"confusion_matrix\": confusion_matrix(y_test, predictions),\n",
    "         \"cross_validation_scores\": cross_val_score(model, X_train, y_train, cv=5) * 100,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "y = clustered_data_4[\"clustered_data\"][\"Severity\"] \n",
    "X = clustered_data_4[\"clustered_data\"].drop(\"Severity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply resampling to the training data\n",
    "resampler = SMOTE(random_state=42)  # You can replace SMOTE with another resampler if needed\n",
    "X_train, y_train = resampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after resampling:\n",
      "Severity\n",
      "0    1112\n",
      "3    1112\n",
      "1    1112\n",
      "2    1112\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print class distribution after resampling\n",
    "print(\"Class distribution after resampling:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classification models with default parameters\n",
    "models = {\n",
    "   \"Decision Tree\": DecisionTreeClassifier(),\n",
    "   \"Random Forest\": RandomForestClassifier(),\n",
    "   \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "   \"Support Vector Machine\": SVC(),\n",
    "   \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "   \"XGBClassifier\": XGBClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold the results\n",
    "all_results = []\n",
    "\n",
    "# Initialize a dictionary to hold the confusion matrices\n",
    "confusion_matrices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "for name, model in models.items():\n",
    "    results = evaluate_model(X_train, y_train, X_test, y_test, name, model)\n",
    "    all_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Results:\n",
      "+------------------------------+------------+-------------+----------+---------+-----------+\n",
      "| model                        |   accuracy |   precision |   recall |      f1 |   roc_auc |\n",
      "|------------------------------+------------+-------------+----------+---------+-----------|\n",
      "| XGBClassifier                |    81.6279 |     82.8257 |  81.6279 | 81.8801 |   95.2479 |\n",
      "| Decision Tree                |    80.2326 |     81.427  |  80.2326 | 80.5345 |   85.8565 |\n",
      "| Gradient Boosting Classifier |    80      |     83.0444 |  80      | 80.4434 |   95.9951 |\n",
      "| Random Forest                |    80      |     80.614  |  80      | 80.1392 |   94.2635 |\n",
      "| K-Nearest Neighbors          |    63.4884 |     70.2258 |  63.4884 | 64.836  |   81.5505 |\n",
      "| Support Vector Machine       |    56.9767 |     68.8401 |  56.9767 | 57.7819 |  nan      |\n",
      "+------------------------------+------------+-------------+----------+---------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the results (excluding the last three items)\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        \"model\": result[\"model\"],\n",
    "        \"accuracy\": result[\"accuracy\"],\n",
    "        \"precision\": result[\"precision\"],\n",
    "        \"recall\": result[\"recall\"],\n",
    "        \"f1\": result[\"f1\"],\n",
    "        \"roc_auc\": result[\"roc_auc\"]\n",
    "    }\n",
    "    for result in all_results\n",
    "])\n",
    "\n",
    "# Sort the DataFrame by F1-score in descending order\n",
    "results_df = results_df.sort_values(by=\"f1\", ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(tabulate(results_df, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reports for XGBClassifier:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85       277\n",
      "           1       0.66      0.72      0.69        46\n",
      "           2       0.66      0.84      0.74        44\n",
      "           3       0.77      0.90      0.83        63\n",
      "\n",
      "    accuracy                           0.82       430\n",
      "   macro avg       0.75      0.82      0.78       430\n",
      "weighted avg       0.83      0.82      0.82       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[224  17  19  17]\n",
      " [ 13  33   0   0]\n",
      " [  7   0  37   0]\n",
      " [  6   0   0  57]]\n",
      "\n",
      "Cross-Validation Scores:\n",
      "[88.98876404 92.92134831 93.48314607 92.68841395 92.80089989]\n"
     ]
    }
   ],
   "source": [
    "# Print the excluded items for XGBClassifier\n",
    "for result in all_results:\n",
    "   if result[\"model\"] == \"XGBClassifier\":\n",
    "      print(\"\\nReports for XGBClassifier:\")\n",
    "      print(\"Classification Report:\")\n",
    "      print(result[\"classification_report\"])\n",
    "      print(\"\\nConfusion Matrix:\")\n",
    "      print(result[\"confusion_matrix\"])\n",
    "      print(\"\\nCross-Validation Scores:\")\n",
    "      print(result[\"cross_validation_scores\"])\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
