{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Creating Severity Levels </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wathsalya/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /home/wathsalya/.local/lib/python3.10/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import silhouette_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import subprocess\n",
    "subprocess.check_call([\"pip\", \"install\", \"tabulate\"])\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"dementia_dataset_1.csv\")\n",
    "\n",
    "# List the columns you want to keep\n",
    "columns_to_keep = [\"Age\",\"Gender\",\"BMI\",\"FamilyHistoryAlzheimers\",\"Hypertension\",\"CardiovascularDisease\",\"MMSE\", \"ADL\", \"FunctionalAssessment\",\"MemoryComplaints\",\"BehavioralProblems\",\"Diagnosis\"]  \n",
    "\n",
    "# Keep only these columns\n",
    "data = data[columns_to_keep]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>FamilyHistoryAlzheimers</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>CardiovascularDisease</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>ADL</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender        BMI  FamilyHistoryAlzheimers  Hypertension  \\\n",
       "0   73       0  22.927749                        0             0   \n",
       "1   89       0  26.827681                        0             0   \n",
       "2   73       0  17.795882                        1             0   \n",
       "3   74       1  33.800817                        0             0   \n",
       "4   89       0  20.716974                        0             0   \n",
       "\n",
       "   CardiovascularDisease       MMSE       ADL  FunctionalAssessment  \\\n",
       "0                      0  21.463532  1.725883              6.518877   \n",
       "1                      0  20.613267  2.592424              7.118696   \n",
       "2                      0   7.356249  7.119548              5.895077   \n",
       "3                      0  13.991127  6.481226              8.965106   \n",
       "4                      0  13.517609  0.014691              6.045039   \n",
       "\n",
       "   MemoryComplaints  BehavioralProblems  Diagnosis  \n",
       "0                 0                   0          0  \n",
       "1                 0                   0          0  \n",
       "2                 0                   0          0  \n",
       "3                 0                   1          0  \n",
       "4                 0                   0          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical features: features with more than 5 unique values are considered numerical\n",
    "num_cols = [\n",
    "    col for col in data.columns if col != \"Diagnosis\" and data[col].nunique() > 5\n",
    "]\n",
    "\n",
    "# Identify categorical features: features that are not numerical and not 'Diagnosis'\n",
    "cat_cols = data.columns.difference(num_cols).difference([\"Diagnosis\"]).to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21.463532\n",
       "1    20.613267\n",
       "2     7.356249\n",
       "3    13.991127\n",
       "4    13.517609\n",
       "Name: MMSE, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['MMSE'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cluster( data, cluster_features, target_column=\"Diagnosis\", n_clusters=3):\n",
    "\n",
    "    # Create a copy of the data\n",
    "    data_clustering = data.copy()\n",
    "\n",
    "    # Cluster ONLY dementia patients\n",
    "    dementia_mask = data_clustering[target_column] == 1\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(data_clustering[dementia_mask][cluster_features])\n",
    "\n",
    "    # Order clusters by MMSE (clinical relevance)\n",
    "    cluster_order = (\n",
    "        data_clustering[dementia_mask]\n",
    "        .groupby(clusters)[\"MMSE\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "        .index\n",
    "    )\n",
    "\n",
    "    # Print MMSE mean of each cluster\n",
    "    mmse_means = (\n",
    "        data_clustering[dementia_mask]\n",
    "        .groupby(clusters)[\"MMSE\"]\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    print(\"MMSE mean of each cluster:\")\n",
    "    print(mmse_means, \"\\n\")\n",
    "\n",
    "    severity_mapping = {cluster_order[0]: 1, cluster_order[1]: 2, cluster_order[2]: 3}\n",
    "\n",
    "    # Update target variable\n",
    "    y = data_clustering[target_column].copy()\n",
    "    y[dementia_mask] = [severity_mapping[c] for c in clusters]\n",
    "    \n",
    "    # Update the clustered data with the new severity levels\n",
    "    data_clustering[\"Severity\"] = y\n",
    "\n",
    "    # Drop the Diagnosis column\n",
    "    data_clustering.drop(columns=[target_column], inplace=True)\n",
    "\n",
    "    # Calculate silhouette score\n",
    "    silhouette_avg = silhouette_score(\n",
    "        data_clustering[dementia_mask][cluster_features], clusters\n",
    "    )\n",
    "        \n",
    "    return {\n",
    "       \"clustered_data\": data_clustering,\n",
    "       \"silhouette_score\": silhouette_avg\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Various Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSE mean of each cluster:\n",
      "1    19.034165\n",
      "0    12.206746\n",
      "2     5.947568\n",
      "Name: MMSE, dtype: float64 \n",
      "\n",
      "Silhouette Score: 0.2388906321196244\n"
     ]
    }
   ],
   "source": [
    "# Filter features to exclude 'diagnose'\n",
    "cluster_features = [col for col in data.columns if col != \"Diagnosis\"]\n",
    "\n",
    "# Process clustering\n",
    "clustered_data = process_cluster(data, cluster_features)\n",
    "\n",
    "# Access results\n",
    "print(\"Silhouette Score:\", clustered_data[\"silhouette_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSE mean of each cluster:\n",
      "2    20.952587\n",
      "0    12.617803\n",
      "1     4.542357\n",
      "Name: MMSE, dtype: float64 \n",
      "\n",
      "Silhouette Score: 0.34887179487214776\n"
     ]
    }
   ],
   "source": [
    "cluster_features_2 = [\"MMSE\", \"FunctionalAssessment\", \"ADL\"]\n",
    "clustered_data_2 = process_cluster(data, cluster_features_2)\n",
    "\n",
    "# Access results\n",
    "print(\"Silhouette Score:\", clustered_data_2[\"silhouette_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSE mean of each cluster:\n",
      "0    21.080635\n",
      "2    12.860176\n",
      "1     4.639195\n",
      "Name: MMSE, dtype: float64 \n",
      "\n",
      "Silhouette Score: 0.4415287253461713\n"
     ]
    }
   ],
   "source": [
    "cluster_features_3 = ['MMSE', 'FunctionalAssessment']\n",
    "clustered_data_3 = process_cluster(data, cluster_features_3)\n",
    "\n",
    "# Access results\n",
    "print(\"Silhouette Score:\", clustered_data_3[\"silhouette_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSE mean of each cluster:\n",
      "2    20.904580\n",
      "0    12.492109\n",
      "1     4.486073\n",
      "Name: MMSE, dtype: float64 \n",
      "\n",
      "Silhouette Score: 0.5858768435462162\n"
     ]
    }
   ],
   "source": [
    "cluster_features_4 = ['MMSE']\n",
    "clustered_data_4 = process_cluster(data, cluster_features_4)\n",
    "\n",
    "# Access results\n",
    "print(\"Silhouette Score:\", clustered_data_4[\"silhouette_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering Silhouette Score and mean MMSE Scores, Cluster 4 is selected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test,name, model):\n",
    "   \n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "         \"model\": name,\n",
    "         \"accuracy\": accuracy_score(y_test, predictions) * 100,\n",
    "         \"precision\": precision_score(y_test, predictions, average=\"weighted\") * 100,  # Updated\n",
    "         \"recall\": recall_score(y_test, predictions, average=\"weighted\") * 100,        # Updated\n",
    "         \"f1\": f1_score(y_test, predictions, average=\"weighted\") * 100,    \n",
    "         \"roc_auc\": roc_auc_score(y_test, model.predict_proba(X_test), multi_class=\"ovr\") * 100\n",
    "         if hasattr(model, \"predict_proba\") else None,  # Htandle models without predict_proba\n",
    "         \"classification_report\": classification_report(y_test, predictions),\n",
    "         \"confusion_matrix\": confusion_matrix(y_test, predictions),\n",
    "         \"cross_validation_scores\": cross_val_score(model, X_train, y_train, cv=5) * 100,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "y = clustered_data_4[\"clustered_data\"][\"Severity\"] \n",
    "X = clustered_data_4[\"clustered_data\"].drop(\"Severity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply resampling to the training data\n",
    "resampler = SMOTE(random_state=42)  # You can replace SMOTE with another resampler if needed\n",
    "X_train, y_train = resampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after resampling:\n",
      "Severity\n",
      "0    1112\n",
      "3    1112\n",
      "1    1112\n",
      "2    1112\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print class distribution after resampling\n",
    "print(\"Class distribution after resampling:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classification models with default parameters\n",
    "models = {\n",
    "   \"Decision Tree\": DecisionTreeClassifier(),\n",
    "   \"Random Forest\": RandomForestClassifier(),\n",
    "   \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "   \"Support Vector Machine\": SVC(),\n",
    "   \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "   \"XGBClassifier\": XGBClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold the results\n",
    "all_results = []\n",
    "\n",
    "# Initialize a dictionary to hold the confusion matrices\n",
    "confusion_matrices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "for name, model in models.items():\n",
    "    results = evaluate_model(X_train, y_train, X_test, y_test, name, model)\n",
    "    all_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Results:\n",
      "+------------------------------+------------+-------------+----------+---------+-----------+\n",
      "| model                        |   accuracy |   precision |   recall |      f1 |   roc_auc |\n",
      "|------------------------------+------------+-------------+----------+---------+-----------|\n",
      "| XGBClassifier                |    81.6279 |     82.8257 |  81.6279 | 81.8801 |   95.2479 |\n",
      "| Decision Tree                |    80.2326 |     81.427  |  80.2326 | 80.5345 |   85.8565 |\n",
      "| Gradient Boosting Classifier |    80      |     83.0444 |  80      | 80.4434 |   95.9951 |\n",
      "| Random Forest                |    80      |     80.614  |  80      | 80.1392 |   94.2635 |\n",
      "| K-Nearest Neighbors          |    63.4884 |     70.2258 |  63.4884 | 64.836  |   81.5505 |\n",
      "| Support Vector Machine       |    56.9767 |     68.8401 |  56.9767 | 57.7819 |  nan      |\n",
      "+------------------------------+------------+-------------+----------+---------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the results (excluding the last three items)\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        \"model\": result[\"model\"],\n",
    "        \"accuracy\": result[\"accuracy\"],\n",
    "        \"precision\": result[\"precision\"],\n",
    "        \"recall\": result[\"recall\"],\n",
    "        \"f1\": result[\"f1\"],\n",
    "        \"roc_auc\": result[\"roc_auc\"]\n",
    "    }\n",
    "    for result in all_results\n",
    "])\n",
    "\n",
    "# Sort the DataFrame by F1-score in descending order\n",
    "results_df = results_df.sort_values(by=\"f1\", ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(tabulate(results_df, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reports for XGBClassifier:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85       277\n",
      "           1       0.66      0.72      0.69        46\n",
      "           2       0.66      0.84      0.74        44\n",
      "           3       0.77      0.90      0.83        63\n",
      "\n",
      "    accuracy                           0.82       430\n",
      "   macro avg       0.75      0.82      0.78       430\n",
      "weighted avg       0.83      0.82      0.82       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[224  17  19  17]\n",
      " [ 13  33   0   0]\n",
      " [  7   0  37   0]\n",
      " [  6   0   0  57]]\n",
      "\n",
      "Cross-Validation Scores:\n",
      "[88.98876404 92.92134831 93.48314607 92.68841395 92.80089989]\n"
     ]
    }
   ],
   "source": [
    "# Print the excluded items for XGBClassifier\n",
    "for result in all_results:\n",
    "   if result[\"model\"] == \"XGBClassifier\":\n",
    "      print(\"\\nReports for XGBClassifier:\")\n",
    "      print(\"Classification Report:\")\n",
    "      print(result[\"classification_report\"])\n",
    "      print(\"\\nConfusion Matrix:\")\n",
    "      print(result[\"confusion_matrix\"])\n",
    "      print(\"\\nCross-Validation Scores:\")\n",
    "      print(result[\"cross_validation_scores\"])\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
